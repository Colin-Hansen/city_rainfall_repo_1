---
title: "City of Calgary Rainfall Data Notebook"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(printr)
library(reshape2)
library(pander)


# added 12-DEC-2020
library(lubridate)
library(scales)
library(rio)
library(knitr)
library(tinytex)
library(tidyverse)
library(summarytools)

panderOptions('knitr.auto.asis', FALSE)
```



```{r compile raw data, include=FALSE}


# create (if necessary) 'data_out' directory
if(dir.exists('data_out') == FALSE) dir.create('data_out')


  # read the site names
  site_names<-read.table('Site Names/Site_Names_and_Ground_Elevations.csv',sep=",",header=TRUE,stringsAsFactors = FALSE)
 
  # extract a vector of the site names
  site_names<-as.character(site_names$Site.Name)
  
  # shorten to first two 2 site names - testing / optional
  site_names <- site_names[1:2]

  # get the names of the raw data subfolders
  subfolder_names<-dir('data_in',full.names = TRUE)
 
  # shorten to first two years of data - testing / optional
  subfolder_names <- subfolder_names[1:2]
  
  
  ## ## ## Start of nested loop ## ## ##
  
  # enter loop along the site names (e.g. 'S01', 'S02', etc.)  
  for (j in seq_along(site_names)) {
  
  # enter loop along the subfolder names (e.g. 1988, 1989, etc.)
  for (i in seq_along(subfolder_names)) {
  
  name<-site_names[j]
  
  # strip the site names from the raw file names in each subfolder
  
  temp_names<-strtrim(dir(subfolder_names[i]),3)
 
  # check to see if the 'name' passed to the function exists in the trimmed file names
  if(name %in% temp_names)  {
    
 
  # the name of the matched file
  file_match_char<-list.files(subfolder_names[i],pattern = name)
  #print(file_match_char)
  
  # the full path pf the matched file
  file_match_path<-file.path(subfolder_names[i],file_match_char)
  #print(file_match_path)
  
   # reference the full path and the input file name using file.path
  infile<-file_match_path
  
  # read raw rainfall data using 'read.table'
  #rainfall_data<-read.table(infile,sep="\t",header=FALSE,skip=3,stringsAsFactors = FALSE)
  
  # read raw rainfall data using 'read_tsv'
  rainfall_data<-read_tsv(infile,col_names = FALSE,trim_ws = TRUE,skip = 3)
  
  colnames(rainfall_data)<-c("Date","Hour.Minute.Seconds","Rainfall")
  # print(str(rainfall_data))
 
  # create a column of Site.Name data
  Site.Name<-rep(name,nrow(rainfall_data))
 
  # get the discrete date - time components
  Year<-year(rainfall_data$Date)
  Month<-month(rainfall_data$Date)
  Week<-week(rainfall_data$Date)
  Day<-mday(rainfall_data$Date)
  Hour<-hour(rainfall_data$Hour.Minute.Seconds)
  Minute<-minute(rainfall_data$Hour.Minute.Seconds)  
  DOY<-yday(rainfall_data$Date)
  Cumulative.Yearly.Rainfall<-cumsum(rainfall_data$Rainfall)
  
  # column bind the data and the date info
  temp_df<-cbind(Site.Name,rainfall_data,Cumulative.Yearly.Rainfall,Year,Month,Week,Day,Hour,Minute,DOY)
 
  # use mutate to add Date-Time from components
  # Reminder: the time zone setting only affects the value when printing
  temp_df <- temp_df %>% mutate(Date.Time=make_datetime(Year,Month,Day,Hour,Minute,tz = "America/Denver"))
  
  # create empty list, on first pass
  if(i == 1) raw_data_list<-list(NULL)
  
  # build a list of the raw data for each site (see Hadley book, page 319)
  raw_data_list[[i]] <- temp_df
 
  }   
    
  else {
    
    print ("No filename match in that subfolder")
  }  
    
    } # end of 'seq_along(subfolder_names)'
    
 
  # create a directory to save the .CSV files
  CSV_master_folder_5_min<-paste0('data_out',"/MASTER_CSV_5_min")
 
  # create (if necessary) 'data_out/MASTER_CSV_5_min' directory
  if(dir.exists(CSV_master_folder_5_min) == FALSE) dir.create(CSV_master_folder_5_min)
  
  # create a file name to save the files for each site
  CSV_file_name<-paste0(name,"_5_min.csv")
  CSV_outfile<-file.path(CSV_master_folder_5_min, CSV_file_name)
    
  # convert the 'raw_data_list' list to a dataframe using ldply from 'plyr' package
  raw_data_XX<-plyr::ldply(raw_data_list,rbind)
  
  # write the results to .CSV file
  write_csv(raw_data_XX,CSV_outfile)   
  
  rm(raw_data_XX)  
  
     
  } # end of 'seq_along(site_names)'
  
 
# *************************************************************


```

```{r summary statistics,include=FALSE}


  # function to return basic summary stastics

  rain_stats_function_1 <- function(files) {
    
      # specify the CSV directory location and path to read the CSV file
      CSV_folder<-'data_out/MASTER_CSV_5_min'
      CSV_infile<-file.path(CSV_folder, files)
      
      # create site name prefix
      site_prefix<-strtrim(files,3)
      print(site_prefix)
      
      # create directory to save statistics results
      stats_folder_1<-'data_out/Statistics_1'
      
      # create (if necessary) directory - ** first part
      if(dir.exists(stats_folder_1) == FALSE) dir.create(stats_folder_1)
      
      # read the rainfall data for one site using 'read_csv'
      rain_5_min<-read_csv(CSV_infile,col_names = TRUE)
      
      # 5 minute rainfall statistics - ** not used but keep for now **
      
      # stats_5_min <- rain_5_min %>% summarize(mean=mean(Rainfall),
      #                                            sd=sd(Rainfall),
      #                                            min=min(Rainfall),
      #                                            Q1=quantile(Rainfall,probs=0.25),
      #                                            median=median(Rainfall),
      #                                            Q3=quantile(Rainfall,probs=0.75),
      #                                            max=max(Rainfall),
      #                                            CV_pct=(sd/mean)*100,
      #                                            total.count=n(),
      #                                            n.valid=sum(!is.na(Rainfall)),
      #                                            pct.valid=(n.valid/total.count)*100)
      # 
      # print(stats_5_min)
      
      # use descr from 'summarytools' package
         
      # set global options for summarytools package
      summarytools::st_options(round.digits = 3)
      
      # stats for only the 'rain_5_min' data
      stats_summary_5_min <- descr(rain_5_min$Rainfall,na.rm = TRUE)
      
      # convert 'descr' output to tibble
      stats_summary_5_min <- tb(stats_summary_5_min)
      
      # transpose the tibble
      stats_summary_5_min <- t(stats_summary_5_min)
      
      # get the hourly rainfall
      # Note: you have to add 'ungroup()' before the select command to extract only the hourly.rainfall *** 
        
      rain_hourly <- rain_5_min %>% group_by(Year,Month,Day,Hour) %>% summarize(summary.rainfall=sum(Rainfall)) %>% ungroup() %>% select(summary.rainfall)
      
      # get the daily rainfall
      
      rain_daily <- rain_5_min %>% group_by(Year,Month,Day) %>% summarize(summary.rainfall=sum(Rainfall)) %>% ungroup() %>% select(summary.rainfall)
      
       # get the monthly rainfall
      
      rain_monthly <- rain_5_min %>% group_by(Year,Month) %>% summarize(summary.rainfall=sum(Rainfall)) %>% ungroup() %>% select(summary.rainfall)
      
       # get the yearly rainfall
      
      rain_yearly <- rain_5_min %>% group_by(Year) %>% summarize(summary.rainfall=sum(Rainfall)) %>% ungroup() %>% select(summary.rainfall)
      
      # create a list of the rain interval results
      
      rain_list_1 <- list(rain_hourly,rain_daily,rain_monthly,rain_yearly)
   
      # create empty dataframe to store the results
      
      stats_df<-data.frame(NULL)

      # enter loop along the rain list
       for (k in seq_along(rain_list_1)) {
   
      # use descr from 'summarytools' package
     
      # note - double square brackets to access individual element of the list
      stats_summary <- descr(rain_list_1[[k]]$summary.rainfall,na.rm = TRUE)

      # convert 'descr' output to tibble
      stats_summary <- tb(stats_summary)
      
      # transpose the tibble
      stats_summary <- t(stats_summary)
      
      # print(stats_summary)
      
      # assign stats result to the dataataframe, only on the first pass
      if(k == 1) {
        stats_df <- stats_summary
      }
      
      # iteratively cbind the results into a dataframe, starting at the second interation
      if(k > 1) {
        stats_df <- cbind(stats_df,stats_summary)
      }
      
    } # end of seq_along 'rain_list_1'
      
      # cbind the 'stats_summary_5_min' results into the dataframe
      stats_df <- cbind(stats_summary_5_min,stats_df)
      
      print(dim(stats_df))
      
      print(class(stats_df))
      
      print(stats_df[1,])
    
      
      # replace the default first row entries (e.g. 'value') with proper column names
      stats_df[1,1:5] <- c("5 Minute","Hourly","Daily","Monthly","Yearly")
      
      # create a file name to save the files for each site
      CSV_file_name<-paste0(site_prefix,"_stats_summary_MASTER.csv")
      CSV_outfile<-file.path(stats_folder_1, CSV_file_name)
        
       # write the results to .CSV file; note: col.names = false to prevent getting 'V1', 'V2' etc. as column names
      write.table(stats_df,CSV_outfile,sep=",",col.names=FALSE,row.names=TRUE)
       
      rm(stats_df)
      
   
  } # end of rain_stats_function_1


  # >>>>>>>  FUNCTION CALL <<<<<<<<<<<<
  
   # the names of the full CSV files
   csv_names<-list.files('data_out/MASTER_CSV_5_min')
   
   lapply(csv_names, function(x) rain_stats_function_1(x))
   
   rm(csv_names)
  
  # *************************************************************

   
``` 

