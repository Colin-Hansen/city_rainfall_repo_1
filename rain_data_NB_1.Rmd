---
title: "City of Calgary Rainfall Data Notebook"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(printr)
# library(ggplot2)
library(reshape2)
library(pander)


# added 12-DEC-2020
# library(dplyr)
# library(tidyr)
# library(purrr)
library(lubridate)
library(scales)
library(rio)
# library(readr)
library(knitr)
library(tinytex)
library(tidyverse)

# EDA packages
library(summarytools)

panderOptions('knitr.auto.asis', FALSE)
```



```{r compile raw data, include=FALSE}


# create (if necessary) 'data_out' directory
if(dir.exists('data_out') == FALSE) dir.create('data_out')


  # read the site names
  site_names<-read.table('Site Names/Site_Names_and_Ground_Elevations.csv',sep=",",header=TRUE,stringsAsFactors = FALSE)
 
  # extract a vector of the site names
  site_names<-as.character(site_names$Site.Name)
  
  # shorten to first two 2 site names - testing / optional
  site_names <- site_names[1:2]

  # get the names of the raw data subfolders
  subfolder_names<-dir('data_in',full.names = TRUE)
 
  # shorten to first two years of data - testing / optional
  subfolder_names <- subfolder_names[1:2]
  
  
  ## ## ## Start of nested loop ## ## ##
  
  # enter loop along the site names (e.g. 'S01', 'S02', etc.)  
  for (j in seq_along(site_names)) {
  
  # enter loop along the subfolder names (e.g. 1988, 1989, etc.)
  for (i in seq_along(subfolder_names)) {
  
  name<-site_names[j]
  
  # strip the site names from the raw file names in each subfolder
  
  temp_names<-strtrim(dir(subfolder_names[i]),3)
 
  # check to see if the 'name' passed to the function exists in the trimmed file names
  if(name %in% temp_names)  {
    
 
  # the name of the matched file
  file_match_char<-list.files(subfolder_names[i],pattern = name)
  #print(file_match_char)
  
  # the full path pf the matched file
  file_match_path<-file.path(subfolder_names[i],file_match_char)
  #print(file_match_path)
  
   # reference the full path and the input file name using file.path
  infile<-file_match_path
  
  # read raw rainfall data using 'read.table'
  #rainfall_data<-read.table(infile,sep="\t",header=FALSE,skip=3,stringsAsFactors = FALSE)
  
  # read raw rainfall data using 'read_tsv'
  rainfall_data<-read_tsv(infile,col_names = FALSE,trim_ws = TRUE,skip = 3)
  
  colnames(rainfall_data)<-c("Date","Hour.Minute.Seconds","Rainfall")
  print(str(rainfall_data))
 
  # create a column of Site.Name data
  Site.Name<-rep(name,nrow(rainfall_data))
 
  # get the discrete date - time components
  Year<-year(rainfall_data$Date)
  Month<-month(rainfall_data$Date)
  Week<-week(rainfall_data$Date)
  Day<-mday(rainfall_data$Date)
  Hour<-hour(rainfall_data$Hour.Minute.Seconds)
  Minute<-minute(rainfall_data$Hour.Minute.Seconds)  
  DOY<-yday(rainfall_data$Date)
  Cumulative.Yearly.Rainfall<-cumsum(rainfall_data$Rainfall)
  
  # column bind the data and the date info
  temp_df<-cbind(Site.Name,rainfall_data,Cumulative.Yearly.Rainfall,Year,Month,Week,Day,Hour,Minute,DOY)
 
  # use mutate to add Date-Time from components
  # Reminder: the time zone setting only affects the value when printing
  temp_df <- temp_df %>% mutate(Date.Time=make_datetime(Year,Month,Day,Hour,Minute,tz = "America/Denver"))
  
  # create empty list, on first pass
  if(i == 1) raw_data_list<-list(NULL)
  
  # build a list of the raw data for each site (see Hadley book, page 319)
  raw_data_list[[i]] <- temp_df
 
  }   
    
  else {
    
    print ("No filename match in that subfolder")
  }  
    
    } # end of 'seq_along(subfolder_names)'
    
 
  # create a directory to save the .CSV files
  CSV_master_folder_5_min<-paste0('data_out',"/MASTER_CSV_5_min")
 
  # create (if necessary) 'data_out/MASTER_CSV_5_min' directory
  if(dir.exists(CSV_master_folder_5_min) == FALSE) dir.create(CSV_master_folder_5_min)
  
  # create a file name to save the files for each site
  CSV_file_name<-paste0(name,"_5_min.csv")
  CSV_outfile<-file.path(CSV_master_folder_5_min, CSV_file_name)
    
  # convert the 'raw_data_list' list to a dataframe using ldply from 'plyr' package
  raw_data_XX<-plyr::ldply(raw_data_list,rbind)
  
  # write the results to .CSV file
  write_csv(raw_data_XX,CSV_outfile)   
  
  rm(raw_data_XX)  
  rm(rainfall_data)
  
     
  } # end of 'seq_along(site_names)'
  
 
# *************************************************************


```

```{r summary statistics,include=FALSE}


  # function to return basic summary stastics (note: requires 'summary tools' package)

  rain_stats_function_1 <- function(files) {
    
      # specify the CSV directory location and path to read the CSV file
      CSV_folder<-'data_out/MASTER_CSV_5_min'
      CSV_infile<-file.path(CSV_folder, files)
      
      # create site name prefix
      site_prefix<-strtrim(files,3)
      print(site_prefix)
      
      # create directory to save statistics results
      stats_folder_1<-'data_out/Statistics_1'
      
      # create (if necessary) directory - ** first part
      if(dir.exists(stats_folder_1) == FALSE) dir.create(stats_folder_1)
      
      # read the rainfall data for one site using 'read_csv'
      rainfall_data<-read_csv(CSV_infile,col_names = TRUE)
      
      # set global options for summarytools package
      summarytools::st_options(round.digits = 3)
      
      # use descr from 'summarytools' package
      stats_summary <- summarytools::descr(rainfall_data$Rainfall,round.digits = st_options("round.digits"),na.rm = TRUE)
      
      
      # stats_summary <- as.data.frame(stats_summary)
      
      # convert to tibble; Note: keep row names using 'NA' option
      # stats_summary <- as.tibble(stats_summary,rownames = NA)
      
      # colnames(stats_summary) <- c("Statistic","Value")
      
      #print(stats_summary) 
      
      
      
      
      # create a file name to save the files for each site
      CSV_file_name<-paste0(site_prefix,"_stats_summary.csv")
      CSV_outfile<-file.path(stats_folder_1, CSV_file_name)
      
      # write the results to .CSV file
      write.table(stats_summary,CSV_outfile,sep=",",col.names=TRUE,row.names=TRUE)
      
      #write_excel_csv(stats_summary)
      
      
    
  }


  # >>>>>>>  FUNCTION CALL <<<<<<<<<<<<
  
   # the names of the full CSV files
   csv_names<-list.files('data_out/MASTER_CSV_5_min')
   
   lapply(csv_names, function(x) rain_stats_function_1(x))
   
   rm(csv_names)
  
  # *************************************************************



  # # get vector of 5-minute raw data filenames - WITH PATH
  # raw_path_filename<-dir('data_out/MASTER_CSV_5_min',full.names = TRUE)
  # 
  # # vector of 5-minute raw data filenames - WITHOUT PATH
  # raw_filename<-dir('data_out/MASTER_CSV_5_min')
  # 
  # 
  #  # enter loop along the raw file names  
  #   for (i in seq_along(raw_path_filename)) {
  # 
  #     # read the rainfall data for one site using 'read_csv'
  #     rainfall_data<-read_csv(raw_path_filename[i],col_names = TRUE)
  #    
  #     # create site name prefix
  #     site_prefix<-strtrim(raw_filename[i],3)
  #     print(site_prefix)
  #     
  #     # create directory to save statistics results
  #     stats_folder_1<-'data_out/Statistics_1'
  #     
  #     # create (if necessary) directory - ** first part
  #     if(dir.exists(stats_folder_1) == FALSE) dir.create(stats_folder_1)
  #     
  #     
  #     
  #     
  #     
  #     # set global options for summarytools package
  #     summarytools::st_options(round.digits = 3)
  #     
  #     # use descr from 'summarytools' package
  #     stats_summary <- summarytools::descr(rainfall_data$Rainfall,round.digits = st_options("round.digits"),na.rm = TRUE)
  #     
  #     # print(stats_summary)
  #     
  #     # create a file name to save the files for each site
  #     CSV_file_name<-paste0(site_prefix,"_stats_summary.csv")
  #     CSV_outfile<-file.path(stats_folder_1, CSV_file_name)
  #     
  #     # write the results to .CSV file
  #     write.table(stats_summary,CSV_outfile,sep=",",col.names=TRUE,row.names=TRUE) 

     
     
      
  
      # create empty list, on first pass
      # if(i == 1) raw_data_list<-list(NULL)
      
      # build a list of the 'stats_summary' results 
      # raw_data_list[[i]] <- temp_df
      
    
    
  # }





```

